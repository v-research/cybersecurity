The objective of this research is to develop of a theory that defines
(all and only) the possible insecurity and security configurations of
any abstract system. The theory is structured upon other theories that 
defines how a component of a system can be abstracted into an agent, defining how
agents can be formalized (both syntactically and semantically) to
describe an abstract system, such as a graph. Some of these theories
(e.g. used for the semantic
definition of the abstract system) are the epistemological definition
of knowledge, the Belief-Desire-Intent and the Assertion-Belief-Fact 
framework of reference, 
mereology, and topological structure. We argue that a mereology is the
most appropriate abstract underlying structure, do to its generality,
for defining the expressiveness of the system abstraction.  Furthermore, a
mereology allows us to define an ontology rather than a taxonomy.  We
also correlate different abstractions of the system to the TRL and the
engineering V-model. 

We implemented a formal theory (of axioms) of a mereotopology, and of
the Region Connection Calculus (RCC3 and RCC5) in a Python program that
uses the Z3 SMT solver. The results show that a single component (i.e.
agent) of an abstract system has a definite number of  different
insecurity configurations (e.g. 53 using RCC5 over a topological
structure) and only 1 secure (i.e. expected) configurations. The
configurations are reported as models satisfying the abstract system
semantics. 

We considered the philosophical definition of truth behind our
approach, rejecting ``proof'' by induction from partial empirical evidences.
Our theory can be applied to system engineering and we show a concrete
application of our theory to the risk assessment of an ad-hoc system.
Finally, we provide a number of ideas to support the engineering of
secure systems (e.g. purely cyber or cyber-physical).
