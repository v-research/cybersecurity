Before going into the details of the literature review, we show that the lack
of agreement on what security is can actually be found in the literature, and
can be categorized with respect to the method of enquiry.  In the following, we
provide three examples based on the categorization provided by Sextus Empiricus
in \autocite{Empiricus1990Pyrrhonism}, since it appear to us to be
comprehensive. ``The natural result of any investigation is that the
investigators either discover the object of search or deny that it is
discoverable and confess it to be in-apprehensible or persist in their search.
[\ldots] This is probably why''\autocite{Empiricus1990Pyrrhonism}: 
\begin{itemize}
	\item The \emph{dogmatists} ``have claimed to have discovered the truth''
		\begin{itemize}
			\item Wikipedia defines cybersecurity in
				\autocite{wiki-cybersecurity} as the protection
				of computer systems and networks from the theft
				of or damage to their hardware, software, or
				electronic data, as well as from the disruption
				or misdirection of the services they provide.
		\end{itemize}
	\item The \emph{academics} ``have asserted that it cannot be apprehended''
		\begin{itemize}
			\item Eugene H. Spafford, Professor at Purdue
				University, defines cybersecurity as follow.
				``The only truly secure system is one that is
				powered off, cast in a block of concrete and
				sealed in a lead-lined room with armed guards —
				and even then I have my doubts.''
				\autocite{Spafford2019Quotes}
		\end{itemize}
	\item The \emph{skeptics} ``go on inquiring''
		\begin{itemize}
			\item Cormac Herley reaches the conclusion that
				cybersecurity has no definition. ``There is an
				inherent asymmetry in computer security: things
				can be declared insecure by observation, but
				not the reverse. There is no test that allows
				us to declare an arbitrary system or technique
				secure. This implies that claims of necessary
				conditions for security are unfalsifiable. ''
				\autocite{Herley2016unfalsifiability}. Therefore, we propose our investigation.
		\end{itemize}
\end{itemize}

\begin{figure}[t]
	\centering
	\includegraphics[width=.6\textwidth]{protocol-example.pdf}
	\caption{Abstraction of an ad-hoc esemplificative protocol execution}
	\label{fig:protocol-example}
\end{figure}

In\autocite{Herley2016unfalsifiability}, Cormac Herley explores what he calls
``an asymmetry in computer security'', which he defines as follows: ``Things
can be declared insecure by observation, but not the reverse. There is no
observation that allows us to declare an arbitrary system or technique
secure''. Herley then uses this argument to show that ``claims that any measure
is necessary for security are empirically unfalsifiable''. Given that, any
theory which is not falsifiable by an empirical experiment is well
known\footnote{``A theory which is not refutable by any conceivable event is
nonscientific. Irrefutability is not a virtue of a theory (as people often
think) but a vice.'' -- Karl Popper, Conjectures and
Refutations\autocite{popper1962conjectures}} to be nonscientific (i.e.
unfalsifiability is a fallacy of a theory), Herley concludes that there is no
scientific theory on cybersecurity; which means that cybersecurity lays in the
realm of pseudo-sciences\autocite{Herley2016usenixvideo}.  Herley, e.g.
in\autocite{Herley2017justifying}, discusses the implications of a
nonscientific approach to cybersecurity, and highlights the tremendous impact on
all the scientific research and engineering of systems; leading often to
terrorism and wars, and wasting of resources in useless protections or
overspending.  While the criticism is investigated
in\autocite{Herley2016unfalsifiability}, no solution is provided.  On the
contrary, the goal of this work \emph{is} to lay the foundations of a
scientific cybersecurity theory. Furthermore, in Section~\ref{sec:sicurezza},
we consider the problem raised by Herley not confined to ``computer security''
but to any abstract system (so that our theory may hold for any sound
implementation such as networks, mechanical, cyber, or cyber-physical system,
or even a single computer or a single device such as an hard-drive).  There is
also an apparent inconsistency in\autocite{Herley2016unfalsifiability} that we
seek to clarify before following (as we agree) the scientific path draw by
Herley: cybersecurity is defined as an abstract property in many formal
approaches to the investigation of the security of systems, and the security of the design of a
formally verified protocol is indeed falsifiable (against the security properties verified).  For example, in the protocol
verification community, security is often defined as a formalization of the
high-level properties confidentiality, integrity, and availability. The problem
in such approaches is not the definition of what cybersecurity is but 
the generality of the results, since they takle a specific step (and not the first) of the engineering process (of system).
Therefore, the theories underlying the verification are based on 
assumptions which non-evidently apply to a general security theory.
As an example, the so called Dolev-Yao attacker model\footnote{For the sake of
simplicity, the Dolev-Yao attacker can be considered as an abstraction of an
active attacker who controls the network but cannot break
cryptography.}\autocite{Dolev1983security}
that only applies to specific instances (often called scenarios) and
abstraction of the protocol. This, in turn, creates a false sense of security
since requires non-justifiable assumptions on the abstraction of the system of which security
is verified. More specifically, for the formal security verification of the system
in Figure~\ref{fig:protocol-example}, a formalized scenario needs to be defined
by a modeler who chooses (among others): (i) a scope of the formalization (e.g.
excluding the server that distributes the public key is often done when
verifying the security of authentication protocols), (ii) the number of
sessions (even tough some approaches do reason on an infinite number of
sessions such as\autocite{Escobar2007maudenpa}), (iii) honesty/dishonesty of
the peers (e.g.  in the ASLan++ language\autocite{Oheimb2010aslan++}), and (iv)
the abstraction of the cryptographic primitives (e.g.  ProVerif vs
CryptoVerif\autocite{Blanchet2017symbolic}).  While many tools and theories
improves the issues we discussed, there is no agreement on which should be
the definitive approach if any and, more importantly, some of the choices made by the modelers/engineers using those formal apporaches may
completely change the results of the formal verification of the system (an interesting example on how difficult it is to 
even just compare the approaches is given in \autocite{Cremers2009comparing}). For
example, under the perfect cryptography assumption\footnote{As defined
in\autocite{Rocchetto2016cpdy}: ``In the so called perfect cryptography
assumption, the security encryption scheme is suppose to be perfect, without
any exploitable flaw, and so the only way for the attacker to decrypt a message
is by using the proper key. That assumption is widely accepted in the security
protocol community, and most of the formal reasoning tools for the analysis of
security protocols abstract away the mathematical and implementation details of
the encryption
scheme\autocite{Turuani2006clatse,Basin2005ofmc,Armando2016satmc,Rocchetto2017interpolation}''}
and assuming that no violation to any security property is done after message
I); in Figure~\ref{fig:protocol-example}, the freedom of choosing the scope
determines that the flaws related to the dishonest impersonation of the Server
may or may not be considered in the verification process.  This choice has
tremendous impact on the focus and findings of the verification of the security
of the protocol.  While this may seem to turn upon minutiae and foreseeable,
this highlights the false sense of security that may derive from a
non-falsifiable theory of system security\footnote{``To the superficial
observer, the analysis of these forms seems to turn upon minutiae. It does in
fact deal with minutiae, but they are of the same order as those dealt with in
microscopic anatomy.'' -- Karl Marx, Capital Volume 1, 1867}.

\subsection{Terminology: Safety or Security}\label{sec:sicurezza}
In most of the natural languages, and in Italian too, the concepts of safety
and security are not syntactically differentiated and both terms (safety and
security) are expressed by the same word, e.g. sicurezza in Italian.  A
semantic distinction between safety and security is correlated to a
belief\footnote{A belief has to be intended as a proposition which is supposed
to be true by the majority of people in our society, without a scientific
underlying theory but based on partial empirical evidences or inductive reasoning based on partial empirical evidences.} that
safety deals with \emph{accidents} (i.e. an unfortunate incident) posed by the
natural environment (e.g. natural events such as wearing of hardware
components) while security deals with \emph{incidents} posed by mankind (e.g.
attackers and bugs).  The fundamental difference between nature and mankind (and,
in turn, between safety and cybersecurity) is believed to be on the different
intents\footnote{``The belief–desire–intention software model (BDI) is a
software model developed for programming intelligent
agents.''\autocite{wiki-bdi}. In the BDI model, the intents represents the
deliberative state of an agent which determines the choice of that agent on
what to do.} (accidents are unfortunate while incidents are not) of the causes
that generates a threat; namely, nature is believed not to have malicious
intents (but unfortunate causes-effects) while threats generated by mankind are
believed to be malicious\footnote{Of course, logical flaws or bugs may be
introduced by other means (e.g. ignorance) without explicit malicious intents,
but the exploitation of those flaws is considered (for now, and detailed
afterwards in the article) malicious, and then we consider any vulnerability to
be malicious even if due to the lack of skills.}.
An overview on the aforementioned aspects of safety and security is depicted in
Figure~\ref{fig:safety-security} and is used as a baseline for a definition of
the terms that structure our current understanding of safety and security. 
\begin{itemize}
	\item \emph{Mankind} ``refers collectively to humans''
\autocite{wiki-mankind}, while the concept of \emph{Nature} is
		related ``to the intrinsic characteristics that plants,
		animals, and other features of the world develop of their own
		accord'' (e.g. the physical universe)\autocite{wiki-nature}. 
		\begin{itemize}
			\item So far, we have used several terms to refer to an
				\emph{attacker}, i.e. threat agent or threat source,
				considering those terms to be semantically
				equivalent.  This ``shallowness'' has raised form the
				necessity of properly citing the different sources, but,
				in the reminder of this paper, we consider the
				Causality principle to be the \emph{threat
				source}, Nature or Mankind to be the
				\emph{threat agents} and an \emph{attacker} as
				a specific malicious threat agent which materializes a
				threat.
		\end{itemize}
	\item \emph{Vulnerability}\footnote{The term vulnerability is not
		present in the Encyclopedia of Cryptography and Security, while
		it is used in 12 entries (such as in the definition of
		``penetration testing''\autocite{caddy2005pentest})
		highlighting how commonly this word is used without a proper
		supporting semantics.}, as defined in\autocite{cnssi20104009}
		(and adopted in\autocite{nist2013800-53}), is ``weakness in an
		information system, system security procedures, internal
		controls, or implementation that could be exploited by a threat
		source''. On the one hand, the definition is broad to enclose
		as much causes (that generates a vulnerability) as possible; on
		the other hand, it derives from empirical evidences (which
		should be considered beliefs\footnote{``For this view, that
		\emph{That Which Is Not} exists, can never predominate. You
		must debar your thought from this way of search, nor let
		ordinary experience in its variety force you along this way,
		(namely, that of allowing) the eye, sightless as it is, and the
		ear, full of sound, and the tongue, to rule; but (you must)
		judge by means of the Reason (Logos) the much-contested proof
		which is expounded by me.'' -- Parmenides of Elea, On Nature
		(circa 500 B.C.), fragments B7.1–8.2
		\autocite{Hakim2016philosophy}} since they are partial results in nature) 
		%while a vulnerability should
		%be defined in a way that is empirically falsifiable. This means
		%that 
		On the other hand, the term vulnerability should have a complete and sound
		definition, so that no other causes (e.g.  other sources) but
		the ones in the definition are responsible for a vulnerability.
		Furthermore, the term ``threat sources'' used in the definition
		in\autocite{cnssi20104009} may be identified with both Nature
		and Mankind, not differentiating between safety and security.
\end{itemize}

\begin{figure}[t]
	\centering
	\includegraphics[width=\textwidth]{safety-security.pdf}
	\caption{Overview of keywords related to security and safety}
	\label{fig:safety-security}
\end{figure}

Most of the safety-preserving principles in the field of engineering of
safety-critical cyber-physical systems (such as elevators and aircraft), upon
which safety requirements are defined (e.g. in standards such as the IEC 61508 or 61511\autocite{IEC201761511}), 
are based on empirical tests and measurements (therefore should be considered hypothesis and not definitions). While reasoning by
induction based on the empirical observation should be avoided, since it may
easily lead to false beliefs, this approach is
often justified by the supposed impossibility of defining a theory that
correctly predicts failures.
%which, in turn, pose hazards to a system. 
To the best of our knowledge, and supported by\autocite{Herley2016unfalsifiability}, %the
there is no scientific theory that defines what a secure system is.
%correlation between predictability of environment and believed unpredictability
%of attackers has not been correlated to a theory on cybersecurity. 
Therefore, 
(inductive\footnote{``So, whenever they argue ``Every man is an
animal and Socrates is a man; therefore Socrates is an animal,'' proposing to
deduce from the universal proposition ``every man is an animal'' the particular
proposition ``Socrates therefore is an animal,'' which in fact goes (as we have
mentioned) to enstablish by way of induction the universal proposition, the
fall into the error of circular reasoning, since they are enstablishing the
universal proposition inductively by means of each of the particulars and
deducing the particular proposition from the universal syllogistically.''
Sextus Empiricus, Outlines of Pyrrhonism II-195
\autocite{Empiricus1990Pyrrhonism}})
research efforts in
predicting malicious effects are accepted (and published) in scientific
conferences (e.g.~\autocite{Rocchetto2014CSRF}). A failure of a wire due to
environment (e.g. due to humidity, dust, heat \&c) is defined from empirical
evidences and processes have been standardized to test qualities of hardware components.
This process completely breaks down when a malicious environment (i.e. an attacker)
is considered instead of the (supposedly honest and predictable)
natural environment. Therefore, the same approach that is in use for safety,
seems not to be applicable for security (e.g. for security testing).

Going back to Figure~\ref{fig:safety-security}, a vulnerability does not
necessarily become a threat for the system, unless exploited ``through a
channel that allows the violation of the security policy
[\ldots]''\autocite{cnssi20104009}. For example, a software or procedure that takes
advantage of the vulnerability causing an \emph{attack} to the system may
result in several correlated incidents and threats.  The process of
exploitation of a defect as a vulnerability is reported in
Figure~\ref{fig:safety-security} such that the difference between exploit and failure,
and attack and accident is to be found just in the maliciousness of the intents
that causes this process (i.e. excluding the intent, the terms are just syntactic transformation from a vulnerability to defect, from
accident to incident). In the following, we conclude the informal definition of
the terms that we used in this section and in Figure~\ref{fig:safety-security}.

\begin{itemize}
	\item \emph{Causality} refers to the causality principle; defined
		in\autocite{Spirkin1983Dialectical} as ``Causality is a genetic
		connection of phenomena through which one thing (the cause)
		under certain conditions gives rise to, causes something else
		(the effect). The essence of causality is the generation and
		determination of one phenomenon by another. In this respect,
		causality differs from various other kinds of connection, for
		example, the simple temporal sequence of phenomena, of the
		regularities of accompanying processes''.
	\item An \emph{Exploit}\footnote{We note that the term exploit is only
		used as a verb in\autocite{ISO2009information}} ``[\ldots]
		(from the English verb to exploit, meaning to use something to
		one’s own advantage) is a piece of software, a chunk of data,
		or a sequence of commands that takes advantage of a bug or
		vulnerability to cause unintended or unanticipated behavior to
		occur on computer software, hardware, or something electronic
		(usually computerized).''\autocite{wiki-exploit}.
	\item An \emph{Attack}, as defined by the International Standard
		ISO/IEC 27000 is an ``attempt to destroy, expose, alter,
		disable, steal or gain unauthorized access to or make
		unauthorized use of an asset''; where an \emph{Asset} is
		``anything that has value to the organization''. We note that for
		the purpose of this article, we do not want to focus on a specific
		organization or business to define asset but, in general, on any 
		abstract organization (e.g. a company or a society).
		We do not consider ethical hackers as attacking a system. 
		In fact, we consider the term \emph{hack} as
		non-malicious (as, e.g. in \autocite{Stallman2002hacker}).
	\item A \emph{Threat}, as defined in\autocite{cnssi20104009}, is ``Any
		circumstance or event with the potential to adversely impact
		organizational operations (including mission, functions, image,
		or reputation), organizational assets, individuals, other
		organizations, or the Nation through an information system via
		unauthorized access, destruction, disclosure, modification of
		information, and/or denial of service''.
	\item \emph{Defect}, ``anything that renders the product not reasonably
		safe''\autocite{Robinson2019writing} (i.e. a characteristic of
		an object which hinders its proper usability).
	\item \emph{Failure}, as defined in\autocite{Merriam2020failure} as ``a state of
		inability to perform a normal function''. The term is
		structured and detailed in
		\autocite{cnssi20104009,iet2017glossary} but relying on an
		abstract notion of failure without a specific definition.
	\item \emph{Hazard}, ``a potential source of
		harm''\autocite{iet2017glossary}.
\end{itemize}

%Either a valid security hypothesis can be formulated based on one or more of
%the concepts reviewed (and depicted in Figure~\ref{fig:safety-security}) or it
%can't.  Since, in the next Section, we will define our security hypothesis (on
%top of which we'll develop a security theory) on those terms, if the second case
%is true we will not formulate a valid security theory. However, while we want
%to highlight that the incompleteness of this review may be a potential issue;
%on the other hand, due to the nature of a literature review, it seems to us
%that only an inductive approach can be used and then any literature review will
%be incomplete.  If the first case applies, in one of those terms one shall find
%a valid ground on top of which formulate a security hypothesis (assuming that a
%valid security hypothesis exists). 

Our literature review shows that most of the definitions relates insecurity to
dis-honesty (also called maliciousness or adversarial) of an agent (often
called adversary or attacker). We can synthesize this belief in the
following hypothesis.

\begin{hypothesis}{\bf Security as Honesty and Insecurity as Dishonesty --}
	\begin{itemize}
		\item a closed system can be considered \emph{secure} if there
			is no dishonest agent
		\item a closed system can be considered \emph{insecure} if
			there is a dishonest agent 
	\end{itemize}
	where an agent is any virtual or physical entity of the system or using
	the system (e.g. a device, a software, or a human being) and dishonesty
	is not necessarily related to malicious motivation but also to
	incompetence or lack of skills.
\end{hypothesis}
As in the Dolev-Yao theory, we may correlate ``being dishonest'' to ``not
following the intended behavior/rules''.  In the case of a generic system, a
dishonest agent is, therefore, any agent that doesn't follow the intended
behavior (or functionality or logic) of the system.  Given the generality of
the definition, and its high level of abstraction, we may
conclude that the hypothesis seems evident. For example, a software can be
considered an agent of the system and whenever it has a bug, it can be
exploited causing an Incident. However, this hypothesis has lead to the
un-testable conclusion that the dishonest behaviors of agents cannot be defined
in general (e.g. due to the heterogeneity of agents and systems) 
and that huge repository of dishonest behaviors should be kept as
definition, such as CWE\autocite{MITRE2020CWEresearch}, CVE\autocite{CVE},
CAPEC\autocite{MITRE2020CAPEC}, NVD\autocite{NIST2020NVD};
or that dishonesty of an agent with respect to a security protocol should be
defined as a number of predefined actions as in
\autocite{Turuani2006clatse,Basin2005ofmc,Armando2016satmc,Rocchetto2017interpolation}
(to name a few). 

We now proceed with a more detailed analysis of the terms
and with the re-formulation of the security hypothesis.
